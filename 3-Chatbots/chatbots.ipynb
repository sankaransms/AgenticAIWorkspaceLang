{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link: https://python.langchain.com/v0.2/docs/tutorials/chatbot/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv() ## aloading all the environment variable\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x000001D8ACF32D20>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x000001D8ACF33DA0>, model_name='Gemma2-9b-It', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "\n",
    "model=ChatGroq(model=\"Gemma2-9b-It\")\n",
    "\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Hello! üëã  \\n\\nHow can I help you today? üòä\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 16, 'prompt_tokens': 10, 'total_tokens': 26, 'completion_time': 0.029090909, 'prompt_time': 3.9e-07, 'queue_time': 0.022318335, 'total_time': 0.029091299}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-43553ca9-1133-46d3-a6b9-5f5112499099-0', usage_metadata={'input_tokens': 10, 'output_tokens': 16, 'total_tokens': 26})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.invoke(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Krish, it's nice to meet you!  \\n\\nThat's a fascinating role. What kind of projects are you working on as Chief AI Engineer? \\n\\nI'm always eager to learn more about how AI is being used in different fields.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 22, 'total_tokens': 78, 'completion_time': 0.101818182, 'prompt_time': 0.00014527, 'queue_time': 0.021124044, 'total_time': 0.101963452}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-ba3d236e-94c9-4bf0-b11a-a6728a805221-0', usage_metadata={'input_tokens': 22, 'output_tokens': 56, 'total_tokens': 78})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage #Huumanmessage is nothing but user_message\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Hi, My name is Krish and I am a Chief AI Engineer\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I don't have personal experiences or a sense of self, so I can't tell you who *you* are.\\n\\nHowever, I can help you explore that question!\\n\\nTo figure out who you are, you might consider:\\n\\n* **Your values:** What's most important to you in life?\\n* **Your passions:** What do you love to do?\\n* **Your strengths and weaknesses:** What are you good at? What could you improve on?\\n* **Your relationships:** Who are the important people in your life?\\n* **Your experiences:** What has shaped who you are today?\\n\\nReflecting on these things can give you a better understanding of yourself.\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 149, 'prompt_tokens': 14, 'total_tokens': 163, 'completion_time': 0.270909091, 'prompt_time': 8.0779e-05, 'queue_time': 0.025426795000000002, 'total_time': 0.27098987}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-b94ed166-5fe9-4269-9722-cbdf6f84a028-0', usage_metadata={'input_tokens': 14, 'output_tokens': 149, 'total_tokens': 163})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage #Huumanmessage is nothing but user_message\n",
    "\n",
    "model.invoke([HumanMessage(content=\"Who I am I?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"You are Krish, and you are a Chief AI Engineer!  \\n\\nIs there anything specific you'd like to discuss about your work as a Chief AI Engineer?  I'm happy to chat about AI trends, ethical considerations, or any challenges you might be facing. üòä \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 60, 'prompt_tokens': 75, 'total_tokens': 135, 'completion_time': 0.109090909, 'prompt_time': 0.002278344, 'queue_time': 0.022616529000000003, 'total_time': 0.111369253}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-61b6fb12-c26c-4bc7-b494-8da0153b639d-0', usage_metadata={'input_tokens': 75, 'output_tokens': 60, 'total_tokens': 135})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage\n",
    "\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi , My name is Krish and I am a Chief AI Engineer\"),\n",
    "        AIMessage(content=\"Hello Krish! It's nice to meet you. \\n\\nAs a Chief AI Engineer, what kind of projects are you working on these days?\\n\\n\"),\n",
    "        HumanMessage(content=\"Hey What's my name and what do I do?\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message History"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link: https://python.langchain.com/v0.2/docs/tutorials/chatbot/#message-history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "with_message_history=RunnableWithMessageHistory(model,get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bound=RunnableBinding(bound=RunnableBinding(bound=RunnableLambda(_enter_history), kwargs={}, config={'run_name': 'load_history'}, config_factories=[])\n",
      "| RunnableBinding(bound=RunnableLambda(_call_runnable_sync), kwargs={}, config={'run_name': 'check_sync_or_async'}, config_factories=[]), kwargs={}, config={'run_name': 'RunnableWithMessageHistory'}, config_factories=[]) kwargs={} config={} config_factories=[] get_session_history=<function get_session_history at 0x000001D8AAB59080> history_factory_config=[ConfigurableFieldSpec(id='session_id', annotation=<class 'str'>, name='Session ID', description='Unique identifier for a session.', default='', is_shared=True, dependencies=None)]\n"
     ]
    }
   ],
   "source": [
    "print(with_message_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"krish1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'session_id': 'krish1'}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Krish,\\n\\nThat's fantastic! It's wonderful to hear that you're so appreciated by the professionals you teach. What subjects do you specialize in?  \\n\\nI'm always interested in learning about people who are passionate about education.  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 22, 'total_tokens': 78, 'completion_time': 0.101818182, 'prompt_time': 0.000382309, 'queue_time': 0.024670538, 'total_time': 0.102200491}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-5ab493c7-8ece-4586-b3f8-5ddec2fd70cd-0', usage_metadata={'input_tokens': 22, 'output_tokens': 56, 'total_tokens': 78})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi , My name is Krish and professionals love me for my teaching\")],\n",
    "    config=config\n",
    ")\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Your name is Krish.  \\n\\nI'm ready for your next question! üòä  What else can I do for you?  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 133, 'total_tokens': 163, 'completion_time': 0.054545455, 'prompt_time': 0.006705191, 'queue_time': 0.022530983, 'total_time': 0.061250646}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-3e3a2780-dc4c-4cd1-b9a8-6717730bb692-0', usage_metadata={'input_tokens': 133, 'output_tokens': 30, 'total_tokens': 163})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What is my name?\")],\n",
    "    config=config,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I don't have access to any personal information about you, including your name. To tell me your name, you can simply type it out! üòä\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## change the config-->session id\n",
    "config1={\"configurable\":{\"session_id\":\"chat2\"}}\n",
    "\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Whats my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hi John! It's nice to meet you.  \\n\\nWhat can I do for you today?\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hey My name is John\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is John!  I remember.  \\n\\nIs there anything else I can help you with, John? üòÑ\\n'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Whats my name\")],\n",
    "    config=config1\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Tempate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",\"You are a helpful assistant.Amnswer all the question to the best of your ability\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt|model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Krish! üëã\\n\\nIt's nice to meet you. \\n\\nWhat can I do for you today? I'm ready to answer your questions and help in any way I can. üòä \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 31, 'total_tokens': 76, 'completion_time': 0.081818182, 'prompt_time': 0.000313059, 'queue_time': 0.024420846, 'total_time': 0.082131241}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-e524a5f2-7372-48fa-8c74-c1c70f7f81e8-0', usage_metadata={'input_tokens': 31, 'output_tokens': 45, 'total_tokens': 76})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Krish\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"As an AI, I don't know who you are. I don't have access to any personal information about you unless you choose to provide it.\\n\\nIs there anything else I can help you with? üòä  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 49, 'prompt_tokens': 30, 'total_tokens': 79, 'completion_time': 0.089090909, 'prompt_time': 0.000574068, 'queue_time': 0.02401877, 'total_time': 0.089664977}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-73fbab7a-7bc9-4edc-b498-0d00ba47b1ff-0', usage_metadata={'input_tokens': 30, 'output_tokens': 49, 'total_tokens': 79})"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"messages\":[HumanMessage(content=\"Who am I?\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapping the chain=prompt|model and get_session_history() using RunnableWithMessageHistory\n",
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Session: chat3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hi Krish! üëã \\n\\nIt's nice to meet you. What can I do for you today?  \\n\\nI'm ready to answer any questions you have to the best of my ability. üòä  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 31, 'total_tokens': 78, 'completion_time': 0.085454545, 'prompt_time': 0.001631715, 'queue_time': 0.024909169000000002, 'total_time': 0.08708626}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-cb57bedf-ab8f-4cc6-99b2-42e1a59705cd-0', usage_metadata={'input_tokens': 31, 'output_tokens': 47, 'total_tokens': 78})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creaing the session\n",
    "config = {\"configurable\": {\"session_id\": \"chat3\"}}\n",
    "\n",
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"Hi My name is Krish\")],\n",
    "    config=config\n",
    ")\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Your name is Krish!  \\n\\nI remember that you told me. üòä  \\n\\n\\n\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    [HumanMessage(content=\"What's my name?\")],\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Add more complexity\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant. Answer all questions to the best of your ability in {language}.\",\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = prompt | model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§ï‡•É‡§∑‡•ç‡§£! ‡§Æ‡•Å‡§ù‡•á ‡§¨‡§π‡•Å‡§§ ‡§ñ‡•Å‡§∂‡•Ä ‡§π‡•à ‡§ï‡§ø ‡§Ü‡§™ ‡§∏‡•á ‡§Æ‡§ø‡§≤‡•Ä‡•§ ‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Ø‡§π‡§æ‡§Å ‡§π‡•Ç‡§Å‡•§ \\n\\n‡§Ü‡§™ ‡§Æ‡•Å‡§ù‡•á ‡§ï‡•ç‡§Ø‡§æ ‡§™‡•Ç‡§õ‡§®‡§æ ‡§ö‡§æ‡§π‡•á‡§Ç‡§ó‡•á? üòä \\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response=chain.invoke({\"messages\":[HumanMessage(content=\"Hi My name is Krish\")],\"language\":\"Hindi\"})\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(\n",
    "    chain,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "session: chat4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§ï‡•É‡§∑‡•ç‡§£! üòä  \\n\\n‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•Ç‡§Å‡•§  \\n\\n‡§Ü‡§™ ‡§ï‡•ç‡§Ø‡§æ ‡§™‡•Ç‡§õ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç?  \\n'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating new session\n",
    "config = {\"configurable\": {\"session_id\": \"chat4\"}}\n",
    "\n",
    "repsonse=with_message_history.invoke(\n",
    "    {'messages': [HumanMessage(content=\"Hi,I am Krish\")],\"language\":\"Hindi\"},\n",
    "    config=config\n",
    ")\n",
    "repsonse.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§ï‡•É‡§∑‡•ç‡§£ ‡§π‡•à‡•§  \\n'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = with_message_history.invoke(\n",
    "    {\"messages\": [HumanMessage(content=\"whats my name?\")], \"language\": \"Hindi\"},\n",
    "    config=config,\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡Æµ‡Æ£‡Æï‡Øç‡Æï‡ÆÆ‡Øç ‡Æö‡Ææ‡Æô‡Øç‡Æï‡Øç! \\n\\n‡Æ®‡Ææ‡Æ©‡Øç ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡ØÅ‡Æï‡Øç‡Æï‡ØÅ ‡Æâ‡Æ§‡Æµ‡Æï‡Øç‡Æï‡ØÇ‡Æü‡Æø‡ÆØ ‡Æí‡Æ∞‡ØÅ ‡Æµ‡Æ¥‡Æø‡Æï‡Ææ‡Æü‡Øç‡Æü‡Æø‡ÆØ‡Ææ‡Æï ‡Æá‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡Æø‡Æ±‡Øá‡Æ©‡Øç. \\n\\n‡Æé‡Æ©‡Øç‡Æ©‡ØÜ‡Æ≤‡Øç‡Æ≤‡Ææ‡ÆÆ‡Øç ‡Æâ‡Æ§‡Æµ‡Æø ‡Æ§‡Øá‡Æµ‡Øà‡Æ™‡Øç‡Æ™‡Æü‡ØÅ‡Æï‡Æø‡Æ±‡Æ§‡ØÅ? üòä \\n'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating new session\n",
    "config = {\"configurable\": {\"session_id\": \"Sank1\"}}\n",
    "\n",
    "repsonse=with_message_history.invoke(\n",
    "    {'messages': [HumanMessage(content=\"Hi,I am Sank\")],\"language\":\"Tamil\"},\n",
    "    config=config\n",
    ")\n",
    "repsonse.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'‡Æ®‡ØÄ ‡Æö‡Ææ‡Æô‡Øç‡Æï‡Øç.  üòä  ‡Æ®‡ØÄ ‡Æé‡Æ©‡Øç‡Æ©‡Øà ‡Æí‡Æ∞‡ØÅ ‡Æµ‡Æ¥‡Æø‡Æï‡Ææ‡Æü‡Øç‡Æü‡Æø‡ÆØ‡Ææ‡Æï ‡Æï‡Øá‡Æü‡Øç‡Æü‡Æø‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡Æø‡Æ±‡Ææ‡ÆØ‡Øç. \\n\\n‡Æé‡Æ©‡Øç‡Æ© ‡Æµ‡Øá‡Æ≤‡Øà ‡Æö‡ØÜ‡ÆØ‡Øç‡ÆØ ‡Æµ‡Øá‡Æ£‡Øç‡Æü‡ØÅ‡ÆÆ‡Øç? üòä \\n'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repsonse=with_message_history.invoke(\n",
    "    {'messages': [HumanMessage(content=\"Who am I?\")],\"language\":\"Tamil\"},\n",
    "    config=config\n",
    ")\n",
    "repsonse.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'krish1': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi , My name is Krish and professionals love me for my teaching', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Krish,\\n\\nThat's fantastic! It's wonderful to hear that you're so appreciated by the professionals you teach. What subjects do you specialize in?  \\n\\nI'm always interested in learning about people who are passionate about education.  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 22, 'total_tokens': 78, 'completion_time': 0.101818182, 'prompt_time': 0.000382309, 'queue_time': 0.024670538, 'total_time': 0.102200491}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-5ab493c7-8ece-4586-b3f8-5ddec2fd70cd-0', usage_metadata={'input_tokens': 22, 'output_tokens': 56, 'total_tokens': 78}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Krish. üòä  \\n\\nI remember that from our first conversation!  Is there anything else I can help you with?\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 90, 'total_tokens': 120, 'completion_time': 0.054545455, 'prompt_time': 0.00670687, 'queue_time': 0.022874868, 'total_time': 0.061252325}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-0ece8692-bcad-4e75-a4bc-bee4bf6c0bf4-0', usage_metadata={'input_tokens': 90, 'output_tokens': 30, 'total_tokens': 120}), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Your name is Krish.  \\n\\nI'm ready for your next question! üòä  What else can I do for you?  \\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 30, 'prompt_tokens': 133, 'total_tokens': 163, 'completion_time': 0.054545455, 'prompt_time': 0.006705191, 'queue_time': 0.022530983, 'total_time': 0.061250646}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-3e3a2780-dc4c-4cd1-b9a8-6717730bb692-0', usage_metadata={'input_tokens': 133, 'output_tokens': 30, 'total_tokens': 163})]),\n",
       " 'chat2': InMemoryChatMessageHistory(messages=[HumanMessage(content='Whats my name', additional_kwargs={}, response_metadata={}), AIMessage(content=\"As an AI, I don't have access to any personal information about you, including your name. To tell me your name, you can simply type it out! üòä\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 38, 'prompt_tokens': 12, 'total_tokens': 50, 'completion_time': 0.069090909, 'prompt_time': 8.514e-05, 'queue_time': 0.022127414999999998, 'total_time': 0.069176049}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-6e8953d5-bda1-42db-947c-657892c005b2-0', usage_metadata={'input_tokens': 12, 'output_tokens': 38, 'total_tokens': 50}), HumanMessage(content='Hey My name is John', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi John! It's nice to meet you.  \\n\\nWhat can I do for you today?\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 63, 'total_tokens': 87, 'completion_time': 0.043636364, 'prompt_time': 0.002067924, 'queue_time': 0.019878481, 'total_time': 0.045704288}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-1e2b56fe-ed7e-4764-a660-e7ac094dde5d-0', usage_metadata={'input_tokens': 63, 'output_tokens': 24, 'total_tokens': 87}), HumanMessage(content='Whats my name', additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is John!  I remember.  \\n\\nIs there anything else I can help you with, John? üòÑ\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 27, 'prompt_tokens': 98, 'total_tokens': 125, 'completion_time': 0.049090909, 'prompt_time': 0.00348299, 'queue_time': 0.025523407999999997, 'total_time': 0.052573899}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-350e3f41-7624-425e-9848-621e7bb1f44e-0', usage_metadata={'input_tokens': 98, 'output_tokens': 27, 'total_tokens': 125})]),\n",
       " 'chat3': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi My name is Krish', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Krish! üëã \\n\\nIt's nice to meet you. What can I do for you today?  \\n\\nI'm ready to answer any questions you have to the best of my ability. üòä  \\n\\n\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 47, 'prompt_tokens': 31, 'total_tokens': 78, 'completion_time': 0.085454545, 'prompt_time': 0.001631715, 'queue_time': 0.024909169000000002, 'total_time': 0.08708626}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-cb57bedf-ab8f-4cc6-99b2-42e1a59705cd-0', usage_metadata={'input_tokens': 31, 'output_tokens': 47, 'total_tokens': 78}), HumanMessage(content=\"What's my name?\", additional_kwargs={}, response_metadata={}), AIMessage(content='Your name is Krish!  \\n\\nI remember that you told me. üòä  \\n\\n\\n\\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 20, 'prompt_tokens': 91, 'total_tokens': 111, 'completion_time': 0.036363636, 'prompt_time': 0.003467951, 'queue_time': 0.020357137, 'total_time': 0.039831587}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-8925fa28-e89a-4240-9ed6-0faef363fbe4-0', usage_metadata={'input_tokens': 91, 'output_tokens': 20, 'total_tokens': 111})]),\n",
       " 'chat4': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi,I am Krish', additional_kwargs={}, response_metadata={}), AIMessage(content='‡§®‡§Æ‡§∏‡•ç‡§§‡•á ‡§ï‡•É‡§∑‡•ç‡§£! üòä  \\n\\n‡§Æ‡•à‡§Ç ‡§Ü‡§™‡§ï‡•Ä ‡§Æ‡§¶‡§¶ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§§‡•à‡§Ø‡§æ‡§∞ ‡§π‡•Ç‡§Å‡•§  \\n\\n‡§Ü‡§™ ‡§ï‡•ç‡§Ø‡§æ ‡§™‡•Ç‡§õ‡§®‡§æ ‡§ö‡§æ‡§π‡§§‡•á ‡§π‡•à‡§Ç?  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 37, 'prompt_tokens': 32, 'total_tokens': 69, 'completion_time': 0.067272727, 'prompt_time': 0.000648138, 'queue_time': 0.023537748, 'total_time': 0.067920865}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-3109b6cb-f185-4f3a-933b-abf2aa37cc71-0', usage_metadata={'input_tokens': 32, 'output_tokens': 37, 'total_tokens': 69}), HumanMessage(content='whats my name?', additional_kwargs={}, response_metadata={}), AIMessage(content='‡§Ü‡§™‡§ï‡§æ ‡§®‡§æ‡§Æ ‡§ï‡•É‡§∑‡•ç‡§£ ‡§π‡•à‡•§  \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 12, 'prompt_tokens': 81, 'total_tokens': 93, 'completion_time': 0.021818182, 'prompt_time': 0.003231661, 'queue_time': 0.026085036, 'total_time': 0.025049843}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-f9f64f93-11df-4e9a-b856-9ae2ba34f440-0', usage_metadata={'input_tokens': 81, 'output_tokens': 12, 'total_tokens': 93})]),\n",
       " 'Sank1': InMemoryChatMessageHistory(messages=[HumanMessage(content='Hi,I am Sank', additional_kwargs={}, response_metadata={}), AIMessage(content='‡Æµ‡Æ£‡Æï‡Øç‡Æï‡ÆÆ‡Øç ‡Æö‡Ææ‡Æô‡Øç‡Æï‡Øç! \\n\\n‡Æ®‡Ææ‡Æ©‡Øç ‡Æâ‡Æô‡Øç‡Æï‡Æ≥‡ØÅ‡Æï‡Øç‡Æï‡ØÅ ‡Æâ‡Æ§‡Æµ‡Æï‡Øç‡Æï‡ØÇ‡Æü‡Æø‡ÆØ ‡Æí‡Æ∞‡ØÅ ‡Æµ‡Æ¥‡Æø‡Æï‡Ææ‡Æü‡Øç‡Æü‡Æø‡ÆØ‡Ææ‡Æï ‡Æá‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡Æø‡Æ±‡Øá‡Æ©‡Øç. \\n\\n‡Æé‡Æ©‡Øç‡Æ©‡ØÜ‡Æ≤‡Øç‡Æ≤‡Ææ‡ÆÆ‡Øç ‡Æâ‡Æ§‡Æµ‡Æø ‡Æ§‡Øá‡Æµ‡Øà‡Æ™‡Øç‡Æ™‡Æü‡ØÅ‡Æï‡Æø‡Æ±‡Æ§‡ØÅ? üòä \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 56, 'prompt_tokens': 32, 'total_tokens': 88, 'completion_time': 0.101818182, 'prompt_time': 0.000307419, 'queue_time': 0.024614996, 'total_time': 0.102125601}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-c87d8509-fd50-41e8-b0c0-a4247e66c124-0', usage_metadata={'input_tokens': 32, 'output_tokens': 56, 'total_tokens': 88}), HumanMessage(content='Who am I?', additional_kwargs={}, response_metadata={}), AIMessage(content='‡Æ®‡ØÄ ‡Æö‡Ææ‡Æô‡Øç‡Æï‡Øç.  üòä  ‡Æ®‡ØÄ ‡Æé‡Æ©‡Øç‡Æ©‡Øà ‡Æí‡Æ∞‡ØÅ ‡Æµ‡Æ¥‡Æø‡Æï‡Ææ‡Æü‡Øç‡Æü‡Æø‡ÆØ‡Ææ‡Æï ‡Æï‡Øá‡Æü‡Øç‡Æü‡Æø‡Æ∞‡ØÅ‡Æï‡Øç‡Æï‡Æø‡Æ±‡Ææ‡ÆØ‡Øç. \\n\\n‡Æé‡Æ©‡Øç‡Æ© ‡Æµ‡Øá‡Æ≤‡Øà ‡Æö‡ØÜ‡ÆØ‡Øç‡ÆØ ‡Æµ‡Øá‡Æ£‡Øç‡Æü‡ØÅ‡ÆÆ‡Øç? üòä \\n', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 45, 'prompt_tokens': 100, 'total_tokens': 145, 'completion_time': 0.081818182, 'prompt_time': 0.00380402, 'queue_time': 0.020197165000000003, 'total_time': 0.085622202}, 'model_name': 'Gemma2-9b-It', 'system_fingerprint': 'fp_10c08bf97d', 'finish_reason': 'stop', 'logprobs': None}, id='run-472b1cfa-af9e-44d2-a484-66ba8ed93d4f-0', usage_metadata={'input_tokens': 100, 'output_tokens': 45, 'total_tokens': 145})])}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Managing the Conversation History\n",
    "One important concept to understand when building chatbots is how to manage conversation history. If left unmanaged, the list of messages will grow unbounded and potentially overflow the context window of the LLM. Therefore, it is important to add a step that limits the size of the messages you are passing in.\n",
    "'trim_messages' helper to reduce how many messages we're sending to the model. The trimmer allows us to specify how many tokens we want to keep, along with other parameters like if we want to always keep the system message and whether to allow partial messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=\"hi! I'm bob\", additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='hi!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='I like vanilla ice cream', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='nice', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='whats 2 + 2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='having fun?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=60,\n",
    "    strategy=\"last\",\n",
    "    token_counter=model,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")\n",
    "messages = [\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! I'm bob\"),\n",
    "    AIMessage(content=\"hi!\"),\n",
    "    HumanMessage(content=\"I like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"whats 2 + 2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "    HumanMessage(content=\"having fun?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]\n",
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You said you like vanilla ice cream! üòä  \\n'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain=(\n",
    "    RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "    | prompt\n",
    "    | model\n",
    "    \n",
    ")\n",
    "response=chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages + [HumanMessage(content=\"What ice cream do i like\")],\n",
    "    \"language\":\"English\"\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'You asked \"whats 2 + 2\" üòä  \\n\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = chain.invoke(\n",
    "    {\n",
    "        \"messages\": messages + [HumanMessage(content=\"what math problem did i ask\")],\n",
    "        \"language\": \"English\",\n",
    "    }\n",
    ")\n",
    "response.content"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
